{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "advisory-church",
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard project preamble\n",
    "from pathgen.utils.seeds import set_seed\n",
    "from pathgen.utils.paths import project_root\n",
    "\n",
    "experiment_name = \"new\"\n",
    "experiment_root = project_root() / \"experiments\" / experiment_name\n",
    "\n",
    "global_seed = 987654321\n",
    "set_seed(global_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "automatic-prince",
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard data science imports\n",
    "import numpy as np\n",
    "\n",
    "# standard pytorch imports\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "# pytorch data loading imports\n",
    "from torch.utils.data import DataLoader, RandomSampler\n",
    "from torchvision.datasets import ImageFolder\n",
    "\n",
    "# torchvision\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "rolled-sunday",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define our hyper parameters\n",
    "batch_size = 64\n",
    "num_epochs = 10\n",
    "learning_rate = 0.01  # 0.001 - takes 25mins (log10 grid search?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "female-baseline",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "muslim-sponsorship",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up the data loaders for training\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])  # these values are what the pretrained models expect\n",
    "])\n",
    "\n",
    "train_set = ImageFolder(experiment_root / 'fake_patches', transform=transform)  # 70,000 samples (35,000 per class) - fake\n",
    "valid_set = ImageFolder(experiment_root / 'valid_patches', transform=transform)  # 30,000 samples (15,000 per class) - non-fake\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True, worker_init_fn=np.random.seed(global_seed), num_workers=32)\n",
    "valid_loader = DataLoader(valid_set, batch_size=batch_size, shuffle=True, worker_init_fn=np.random.seed(global_seed), num_workers=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "viral-killer",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(epoch, model, optimizer, path):\n",
    "    print(f\"saving checkpoint to {path}\")\n",
    "    state = { 'epoch': epoch, \n",
    "              'model_state_dict': model.state_dict(),\n",
    "              'optimizer_state_dict': optimizer.state_dict() }\n",
    "    torch.save(state, path)\n",
    "\n",
    "def load_checkpoint(model, optimizer, path):\n",
    "    print(\"loading checkpoint\")\n",
    "    state = torch.load(path)\n",
    "    epoch = state[\"epoch\"]\n",
    "    model.load_state_dict(state[\"state_dict\"])\n",
    "    optimizer.load_state_dict(state[\"optimizer\"])\n",
    "    return epoch, model, optimizer, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "experienced-undergraduate",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preamble\n",
    "from torchinfo import summary\n",
    "\n",
    "# get and example image from the dataset so we can generate the summaries\n",
    "img, _ = train_set[0]\n",
    "img = img.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "statewide-circuit",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_resnet18 = torchvision.models.resnet18(pretrained=False)\n",
    "model_resnet18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "threatened-heritage",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "ResNet                                   --                        --\n",
       "├─Conv2d: 1-1                            [64, 64, 32, 32]          9,408\n",
       "├─BatchNorm2d: 1-2                       [64, 64, 32, 32]          128\n",
       "├─ReLU: 1-3                              [64, 64, 32, 32]          --\n",
       "├─MaxPool2d: 1-4                         [64, 64, 16, 16]          --\n",
       "├─Sequential: 1-5                        [64, 64, 16, 16]          --\n",
       "│    └─BasicBlock: 2-1                   [64, 64, 16, 16]          --\n",
       "│    │    └─Conv2d: 3-1                  [64, 64, 16, 16]          36,864\n",
       "│    │    └─BatchNorm2d: 3-2             [64, 64, 16, 16]          128\n",
       "│    │    └─ReLU: 3-3                    [64, 64, 16, 16]          --\n",
       "│    │    └─Conv2d: 3-4                  [64, 64, 16, 16]          36,864\n",
       "│    │    └─BatchNorm2d: 3-5             [64, 64, 16, 16]          128\n",
       "│    │    └─ReLU: 3-6                    [64, 64, 16, 16]          --\n",
       "│    └─BasicBlock: 2-2                   [64, 64, 16, 16]          --\n",
       "│    │    └─Conv2d: 3-7                  [64, 64, 16, 16]          36,864\n",
       "│    │    └─BatchNorm2d: 3-8             [64, 64, 16, 16]          128\n",
       "│    │    └─ReLU: 3-9                    [64, 64, 16, 16]          --\n",
       "│    │    └─Conv2d: 3-10                 [64, 64, 16, 16]          36,864\n",
       "│    │    └─BatchNorm2d: 3-11            [64, 64, 16, 16]          128\n",
       "│    │    └─ReLU: 3-12                   [64, 64, 16, 16]          --\n",
       "├─Sequential: 1-6                        [64, 128, 8, 8]           --\n",
       "│    └─BasicBlock: 2-3                   [64, 128, 8, 8]           --\n",
       "│    │    └─Conv2d: 3-13                 [64, 128, 8, 8]           73,728\n",
       "│    │    └─BatchNorm2d: 3-14            [64, 128, 8, 8]           256\n",
       "│    │    └─ReLU: 3-15                   [64, 128, 8, 8]           --\n",
       "│    │    └─Conv2d: 3-16                 [64, 128, 8, 8]           147,456\n",
       "│    │    └─BatchNorm2d: 3-17            [64, 128, 8, 8]           256\n",
       "│    │    └─Sequential: 3-18             [64, 128, 8, 8]           8,448\n",
       "│    │    └─ReLU: 3-19                   [64, 128, 8, 8]           --\n",
       "│    └─BasicBlock: 2-4                   [64, 128, 8, 8]           --\n",
       "│    │    └─Conv2d: 3-20                 [64, 128, 8, 8]           147,456\n",
       "│    │    └─BatchNorm2d: 3-21            [64, 128, 8, 8]           256\n",
       "│    │    └─ReLU: 3-22                   [64, 128, 8, 8]           --\n",
       "│    │    └─Conv2d: 3-23                 [64, 128, 8, 8]           147,456\n",
       "│    │    └─BatchNorm2d: 3-24            [64, 128, 8, 8]           256\n",
       "│    │    └─ReLU: 3-25                   [64, 128, 8, 8]           --\n",
       "├─Sequential: 1-7                        [64, 256, 4, 4]           --\n",
       "│    └─BasicBlock: 2-5                   [64, 256, 4, 4]           --\n",
       "│    │    └─Conv2d: 3-26                 [64, 256, 4, 4]           294,912\n",
       "│    │    └─BatchNorm2d: 3-27            [64, 256, 4, 4]           512\n",
       "│    │    └─ReLU: 3-28                   [64, 256, 4, 4]           --\n",
       "│    │    └─Conv2d: 3-29                 [64, 256, 4, 4]           589,824\n",
       "│    │    └─BatchNorm2d: 3-30            [64, 256, 4, 4]           512\n",
       "│    │    └─Sequential: 3-31             [64, 256, 4, 4]           33,280\n",
       "│    │    └─ReLU: 3-32                   [64, 256, 4, 4]           --\n",
       "│    └─BasicBlock: 2-6                   [64, 256, 4, 4]           --\n",
       "│    │    └─Conv2d: 3-33                 [64, 256, 4, 4]           589,824\n",
       "│    │    └─BatchNorm2d: 3-34            [64, 256, 4, 4]           512\n",
       "│    │    └─ReLU: 3-35                   [64, 256, 4, 4]           --\n",
       "│    │    └─Conv2d: 3-36                 [64, 256, 4, 4]           589,824\n",
       "│    │    └─BatchNorm2d: 3-37            [64, 256, 4, 4]           512\n",
       "│    │    └─ReLU: 3-38                   [64, 256, 4, 4]           --\n",
       "├─Sequential: 1-8                        [64, 512, 2, 2]           --\n",
       "│    └─BasicBlock: 2-7                   [64, 512, 2, 2]           --\n",
       "│    │    └─Conv2d: 3-39                 [64, 512, 2, 2]           1,179,648\n",
       "│    │    └─BatchNorm2d: 3-40            [64, 512, 2, 2]           1,024\n",
       "│    │    └─ReLU: 3-41                   [64, 512, 2, 2]           --\n",
       "│    │    └─Conv2d: 3-42                 [64, 512, 2, 2]           2,359,296\n",
       "│    │    └─BatchNorm2d: 3-43            [64, 512, 2, 2]           1,024\n",
       "│    │    └─Sequential: 3-44             [64, 512, 2, 2]           132,096\n",
       "│    │    └─ReLU: 3-45                   [64, 512, 2, 2]           --\n",
       "│    └─BasicBlock: 2-8                   [64, 512, 2, 2]           --\n",
       "│    │    └─Conv2d: 3-46                 [64, 512, 2, 2]           2,359,296\n",
       "│    │    └─BatchNorm2d: 3-47            [64, 512, 2, 2]           1,024\n",
       "│    │    └─ReLU: 3-48                   [64, 512, 2, 2]           --\n",
       "│    │    └─Conv2d: 3-49                 [64, 512, 2, 2]           2,359,296\n",
       "│    │    └─BatchNorm2d: 3-50            [64, 512, 2, 2]           1,024\n",
       "│    │    └─ReLU: 3-51                   [64, 512, 2, 2]           --\n",
       "├─AdaptiveAvgPool2d: 1-9                 [64, 512, 1, 1]           --\n",
       "├─Sequential: 1-10                       [64, 2]                   --\n",
       "│    └─Linear: 2-9                       [64, 2]                   1,026\n",
       "==========================================================================================\n",
       "Total params: 11,177,538\n",
       "Trainable params: 11,177,538\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 9.48\n",
       "==========================================================================================\n",
       "Input size (MB): 3.15\n",
       "Forward/backward pass size (MB): 207.62\n",
       "Params size (MB): 44.71\n",
       "Estimated Total Size (MB): 255.48\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_resnet18.fc = nn.Sequential(nn.Linear(in_features=512, out_features=2, bias=True))\n",
    "\n",
    "# get a summary of the model based on our input shape\n",
    "model_resnet18.to(device)\n",
    "input_size = tuple([batch_size]) + tuple(img.shape)\n",
    "summary(model_resnet18, input_size=input_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "lasting-magic",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statistics import mean\n",
    "\n",
    "class LoggedVariable:\n",
    "    def __init__(self):\n",
    "        self.batch_values = []\n",
    "        self.epoch_values = []\n",
    "        \n",
    "    def append(self, value):\n",
    "        self.batch_values.append(value)\n",
    "        \n",
    "    def end_epoch(self):\n",
    "        mean_batch_values = mean(self.batch_values)\n",
    "        self.epoch_values.append(mean_batch_values)\n",
    "        self.batch_values = []\n",
    "        \n",
    "class Logger:\n",
    "    def __init__(self):\n",
    "        self.variables = {}\n",
    "    \n",
    "    def __call__(self, key, value):\n",
    "        if key not in self.variables:\n",
    "            self.variables[key] = LoggedVariable()\n",
    "        self.variables[key].append(value)\n",
    "    \n",
    "    def end_epoch(self, epoch):\n",
    "        print(f\"end epoch {epoch}\", end = '')\n",
    "        for key, val in self.variables.items():\n",
    "            val.end_epoch()\n",
    "            print(f\" {key}: {val.epoch_values[epoch]:.2f}\", end = '')\n",
    "        print()\n",
    "    \n",
    "    def history(self):\n",
    "        return { k:v.epoch_values for k, v in self.variables.items() }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "clinical-insider",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(logits, y):\n",
    "    pred = torch.log_softmax(logits, dim=1)\n",
    "    correct = pred.argmax(dim=1).eq(y).sum().item()\n",
    "    total = len(y)\n",
    "    acc = correct / total\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "peripheral-wheel",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitting model: ResNet for 10 epochs.\n",
      "Epoch 0\n",
      "train.\t\tepoch: 0\tbatch: 1094/1094\tloss: 0.000\taccuracy: 1.000 \n",
      "validate.\tepoch: 0\tbatch: 469/469\t\tloss: 1.184\taccuracy: 0.479 \n",
      "saving checkpoint to /home/ubuntu/pathgen/experiments/new/ResNet_fakedata_checkpoint_0.ckpt\n",
      "end epoch 0 train_acc: 0.98 train_loss: 0.04 valid_acc: 0.55 valid_loss: 0.95\n",
      "\n",
      "Epoch 1\n",
      "train.\t\tepoch: 1\tbatch: 1094/1094\tloss: 0.000\taccuracy: 1.000 \n",
      "validate.\tepoch: 1\tbatch: 469/469\t\tloss: 0.798\taccuracy: 0.667 \n",
      "saving checkpoint to /home/ubuntu/pathgen/experiments/new/ResNet_fakedata_checkpoint_1.ckpt\n",
      "end epoch 1 train_acc: 1.00 train_loss: 0.00 valid_acc: 0.64 valid_loss: 0.88\n",
      "\n",
      "Epoch 2\n",
      "train.\t\tepoch: 2\tbatch: 1094/1094\tloss: 0.000\taccuracy: 1.000 \n",
      "validate.\tepoch: 2\tbatch: 469/469\t\tloss: 0.930\taccuracy: 0.604 \n",
      "saving checkpoint to /home/ubuntu/pathgen/experiments/new/ResNet_fakedata_checkpoint_2.ckpt\n",
      "end epoch 2 train_acc: 1.00 train_loss: 0.00 valid_acc: 0.60 valid_loss: 0.90\n",
      "\n",
      "Epoch 3\n",
      "train.\t\tepoch: 3\tbatch: 1094/1094\tloss: 0.000\taccuracy: 1.000 \n",
      "validate.\tepoch: 3\tbatch: 469/469\t\tloss: 0.801\taccuracy: 0.625 \n",
      "saving checkpoint to /home/ubuntu/pathgen/experiments/new/ResNet_fakedata_checkpoint_3.ckpt\n",
      "end epoch 3 train_acc: 1.00 train_loss: 0.00 valid_acc: 0.63 valid_loss: 0.76\n",
      "\n",
      "Epoch 4\n",
      "train.\t\tepoch: 4\tbatch: 1094/1094\tloss: 0.000\taccuracy: 1.000 \n",
      "validate.\tepoch: 4\tbatch: 469/469\t\tloss: 1.065\taccuracy: 0.542 \n",
      "saving checkpoint to /home/ubuntu/pathgen/experiments/new/ResNet_fakedata_checkpoint_4.ckpt\n",
      "end epoch 4 train_acc: 1.00 train_loss: 0.00 valid_acc: 0.61 valid_loss: 0.85\n",
      "\n",
      "Epoch 5\n",
      "train.\t\tepoch: 5\tbatch: 1094/1094\tloss: 0.000\taccuracy: 1.000 \n",
      "validate.\tepoch: 5\tbatch: 469/469\t\tloss: 0.682\taccuracy: 0.646 \n",
      "saving checkpoint to /home/ubuntu/pathgen/experiments/new/ResNet_fakedata_checkpoint_5.ckpt\n",
      "end epoch 5 train_acc: 1.00 train_loss: 0.00 valid_acc: 0.61 valid_loss: 0.81\n",
      "\n",
      "Epoch 6\n",
      "train.\t\tepoch: 6\tbatch: 1094/1094\tloss: 0.000\taccuracy: 1.000 \n",
      "validate.\tepoch: 6\tbatch: 469/469\t\tloss: 0.567\taccuracy: 0.792 \n",
      "saving checkpoint to /home/ubuntu/pathgen/experiments/new/ResNet_fakedata_checkpoint_6.ckpt\n",
      "end epoch 6 train_acc: 1.00 train_loss: 0.00 valid_acc: 0.62 valid_loss: 0.80\n",
      "\n",
      "Epoch 7\n",
      "train.\t\tepoch: 7\tbatch: 1094/1094\tloss: 0.000\taccuracy: 1.000 \n",
      "validate.\tepoch: 7\tbatch: 469/469\t\tloss: 0.925\taccuracy: 0.521 \n",
      "saving checkpoint to /home/ubuntu/pathgen/experiments/new/ResNet_fakedata_checkpoint_7.ckpt\n",
      "end epoch 7 train_acc: 1.00 train_loss: 0.00 valid_acc: 0.62 valid_loss: 0.81\n",
      "\n",
      "Epoch 8\n",
      "train.\t\tepoch: 8\tbatch: 1094/1094\tloss: 0.000\taccuracy: 1.000 \n",
      "validate.\tepoch: 8\tbatch: 469/469\t\tloss: 1.183\taccuracy: 0.521 \n",
      "saving checkpoint to /home/ubuntu/pathgen/experiments/new/ResNet_fakedata_checkpoint_8.ckpt\n",
      "end epoch 8 train_acc: 1.00 train_loss: 0.00 valid_acc: 0.60 valid_loss: 0.91\n",
      "\n",
      "Epoch 9\n",
      "train.\t\tepoch: 9\tbatch: 1094/1094\tloss: 0.000\taccuracy: 1.000 \n",
      "validate.\tepoch: 9\tbatch: 469/469\t\tloss: 0.937\taccuracy: 0.625 \n",
      "saving checkpoint to /home/ubuntu/pathgen/experiments/new/ResNet_fakedata_checkpoint_9.ckpt\n",
      "end epoch 9 train_acc: 1.00 train_loss: 0.00 valid_acc: 0.62 valid_loss: 0.79\n",
      "\n",
      "training complete.\n",
      "Time total:     674.08 sec\n",
      "Time per epoch: 67.41 sec\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "import json\n",
    "\n",
    "model = model_resnet18\n",
    "\n",
    "print(f'fitting model: {type(model).__name__} for {num_epochs} epochs.')\n",
    "\n",
    "# set up the optimizer\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9, weight_decay=0.001)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.5)\n",
    "\n",
    "# initalise stats\n",
    "log = Logger()\n",
    "start_time_sec = time()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"Epoch {epoch}\")\n",
    "    \n",
    "    # train and evaluate on the training set\n",
    "    model.train()\n",
    "    for batch_idx, (X, y) in enumerate(train_loader):\n",
    "        # put X and y for the batch on the GPU is possible\n",
    "        X = X.to(device)\n",
    "        y = y.to(device)\n",
    "\n",
    "        # forward pass\n",
    "        logits = model(X)\n",
    "        loss = criterion(logits, y)\n",
    "\n",
    "        # backwards pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        # gradient descent\n",
    "        optimizer.step()\n",
    "\n",
    "        # log the metrics\n",
    "        acc = accuracy(logits, y)\n",
    "        log('train_acc', acc)\n",
    "        log('train_loss', loss.item())\n",
    "\n",
    "        print('\\r', f'train.\\t\\tepoch: {epoch}\\tbatch: {batch_idx + 1}/{len(train_loader)}\\tloss: {loss:.3f}\\taccuracy: {acc:.3f} ', sep='', end='', flush=True)\n",
    "        # print(torch.log_softmax(logits, dim=1).argmax(dim=1), y)\n",
    "        # print(f'train.\\t\\tepoch: {epoch}\\tbatch: {batch_idx + 1}/{len(train_loader)}\\tloss: {loss:.3f}\\taccuracy: {acc:.3f}')\n",
    "    print()\n",
    "\n",
    "    # evaluate on the validation set\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (X, y) in enumerate(valid_loader):\n",
    "            # put X and y for the batch on the GPU is possible\n",
    "            X = X.to(device)\n",
    "            y = y.to(device)\n",
    "\n",
    "            # forward pass\n",
    "            logits = model(X)\n",
    "            loss = criterion(logits, y)\n",
    "\n",
    "            # computer the metric and log them\n",
    "            acc = accuracy(logits, y)\n",
    "            log('valid_acc', acc)\n",
    "            log('valid_loss', loss.item())\n",
    "\n",
    "            print('\\r', f'validate.\\tepoch: {epoch}\\tbatch: {batch_idx + 1}/{len(valid_loader)}\\t\\tloss: {loss:.3f}\\taccuracy: {acc:.3f} ', sep='', end='', flush=True)        \n",
    "\n",
    "    print()\n",
    "\n",
    "    save_checkpoint(epoch, model, optimizer, experiment_root / f\"{type(model).__name__}_fakedata_checkpoint_{epoch}.ckpt\") \n",
    "    log.end_epoch(epoch)\n",
    "\n",
    "    scheduler.step()\n",
    "    print()\n",
    "\n",
    "end_time_sec       = time()\n",
    "total_time_sec     = end_time_sec - start_time_sec\n",
    "time_per_epoch_sec = total_time_sec / num_epochs\n",
    "print(\"training complete.\")\n",
    "print('Time total:     %5.2f sec' % (total_time_sec))\n",
    "print('Time per epoch: %5.2f sec' % (time_per_epoch_sec))\n",
    "print()\n",
    "\n",
    "history = log.history()\n",
    "\n",
    "# save the results\n",
    "json.dump(history, open(experiment_root / f\"results_{type(model).__name__}_fakedata.json\", \"w\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "painful-lightning",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test\n",
    "test_set = ImageFolder(experiment_root / 'test_patches', transform=transform)\n",
    "test_loader = DataLoader(test_set, batch_size=batch_size, worker_init_fn=np.random.seed(global_seed), num_workers=32)\n",
    "\n",
    "expected, predicted = [], []\n",
    "\n",
    "# evaluate on the test set\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for batch_idx, (X, y) in enumerate(test_loader):\n",
    "        # put X and y for the batch on the GPU is possible\n",
    "        X = X.to(device)\n",
    "        y = y.to(device)\n",
    "\n",
    "        # forward pass\n",
    "        logits = model(X)\n",
    "\n",
    "        # computer the metric and log them\n",
    "        pred = torch.log_softmax(logits, dim=1).argmax(dim=1)\n",
    "        predicted.extend(pred.cpu().tolist())\n",
    "        expected.extend(y.cpu().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "comfortable-gateway",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      normal       0.60      0.56      0.58     15000\n",
      "       tumor       0.59      0.63      0.61     15000\n",
      "\n",
      "    accuracy                           0.60     30000\n",
      "   macro avg       0.60      0.60      0.60     30000\n",
      "weighted avg       0.60      0.60      0.60     30000\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(metrics.classification_report(expected, predicted, labels=[0, 1], target_names=['normal', 'tumor']))\n",
    "\n",
    "cm = metrics.confusion_matrix(expected, predicted)\n",
    "\n",
    "ax = plt.subplot()\n",
    "sns.heatmap(cm, annot=True, ax = ax, fmt='g', cmap='Blues');\n",
    "\n",
    "# labels, title and ticks\n",
    "ax.set_xlabel('Predicted labels');\n",
    "ax.set_ylabel('True labels'); \n",
    "ax.set_title('Patch Classifier Real Data Confusion Matrix'); \n",
    "ax.xaxis.set_ticklabels(['normal', 'tumor']); ax.yaxis.set_ticklabels(['normal', 'tumor']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "weekly-coordinator",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pathgen",
   "language": "python",
   "name": "pathgen"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
