{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "foster-traveler",
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard project preamble\n",
    "from pathgen.utils.seeds import set_seed\n",
    "from pathgen.utils.paths import project_root\n",
    "\n",
    "experiment_name = \"new\"\n",
    "experiment_root = project_root() / \"experiments\" / experiment_name\n",
    "\n",
    "global_seed = 987654321\n",
    "set_seed(global_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "rapid-plate",
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard data science imports\n",
    "import numpy as np\n",
    "\n",
    "# standard pytorch imports\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "# pytorch data loading imports\n",
    "from torch.utils.data import DataLoader, RandomSampler\n",
    "from torchvision.datasets import ImageFolder\n",
    "\n",
    "# torchvision\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "optional-tourist",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define our hyper parameters\n",
    "batch_size = 64\n",
    "num_epochs = 30\n",
    "learning_rate = 0.01  # 0.001 - takes 25mins (log10 grid search?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "checked-foundation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "paperback-world",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up the data loaders for training\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])  # these values are what the pretrained models expect\n",
    "])\n",
    "\n",
    "train_set = ImageFolder(experiment_root / 'train_patches', transform=transform)  # 70,000 samples (35,000 per class) - non-fake\n",
    "valid_set = ImageFolder(experiment_root / 'valid_patches', transform=transform)  # 30,000 samples (15,000 per class) - non-fake\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True, worker_init_fn=np.random.seed(global_seed), num_workers=32)\n",
    "valid_loader = DataLoader(valid_set, batch_size=batch_size, shuffle=True, worker_init_fn=np.random.seed(global_seed), num_workers=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "pleased-compatibility",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(epoch, model, optimizer, path):\n",
    "    print(f\"saving checkpoint to {path}\")\n",
    "    state = { 'epoch': epoch, \n",
    "              'model_state_dict': model.state_dict(),\n",
    "              'optimizer_state_dict': optimizer.state_dict() }\n",
    "    torch.save(state, path)\n",
    "\n",
    "def load_checkpoint(model, optimizer, path):\n",
    "    print(\"loading checkpoint\")\n",
    "    state = torch.load(path)\n",
    "    epoch = state[\"epoch\"]\n",
    "    model.load_state_dict(state[\"state_dict\"])\n",
    "    optimizer.load_state_dict(state[\"optimizer\"])\n",
    "    return epoch, model, optimizer, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "streaming-atlantic",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preamble\n",
    "from torchinfo import summary\n",
    "\n",
    "# get and example image from the dataset so we can generate the summaries\n",
    "img, _ = train_set[0]\n",
    "img = img.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "designing-crime",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_resnet18 = torchvision.models.resnet18(pretrained=False)\n",
    "model_resnet18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "otherwise-result",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "ResNet                                   --                        --\n",
       "├─Conv2d: 1-1                            [64, 64, 128, 128]        9,408\n",
       "├─BatchNorm2d: 1-2                       [64, 64, 128, 128]        128\n",
       "├─ReLU: 1-3                              [64, 64, 128, 128]        --\n",
       "├─MaxPool2d: 1-4                         [64, 64, 64, 64]          --\n",
       "├─Sequential: 1-5                        [64, 64, 64, 64]          --\n",
       "│    └─BasicBlock: 2-1                   [64, 64, 64, 64]          --\n",
       "│    │    └─Conv2d: 3-1                  [64, 64, 64, 64]          36,864\n",
       "│    │    └─BatchNorm2d: 3-2             [64, 64, 64, 64]          128\n",
       "│    │    └─ReLU: 3-3                    [64, 64, 64, 64]          --\n",
       "│    │    └─Conv2d: 3-4                  [64, 64, 64, 64]          36,864\n",
       "│    │    └─BatchNorm2d: 3-5             [64, 64, 64, 64]          128\n",
       "│    │    └─ReLU: 3-6                    [64, 64, 64, 64]          --\n",
       "│    └─BasicBlock: 2-2                   [64, 64, 64, 64]          --\n",
       "│    │    └─Conv2d: 3-7                  [64, 64, 64, 64]          36,864\n",
       "│    │    └─BatchNorm2d: 3-8             [64, 64, 64, 64]          128\n",
       "│    │    └─ReLU: 3-9                    [64, 64, 64, 64]          --\n",
       "│    │    └─Conv2d: 3-10                 [64, 64, 64, 64]          36,864\n",
       "│    │    └─BatchNorm2d: 3-11            [64, 64, 64, 64]          128\n",
       "│    │    └─ReLU: 3-12                   [64, 64, 64, 64]          --\n",
       "├─Sequential: 1-6                        [64, 128, 32, 32]         --\n",
       "│    └─BasicBlock: 2-3                   [64, 128, 32, 32]         --\n",
       "│    │    └─Conv2d: 3-13                 [64, 128, 32, 32]         73,728\n",
       "│    │    └─BatchNorm2d: 3-14            [64, 128, 32, 32]         256\n",
       "│    │    └─ReLU: 3-15                   [64, 128, 32, 32]         --\n",
       "│    │    └─Conv2d: 3-16                 [64, 128, 32, 32]         147,456\n",
       "│    │    └─BatchNorm2d: 3-17            [64, 128, 32, 32]         256\n",
       "│    │    └─Sequential: 3-18             [64, 128, 32, 32]         8,448\n",
       "│    │    └─ReLU: 3-19                   [64, 128, 32, 32]         --\n",
       "│    └─BasicBlock: 2-4                   [64, 128, 32, 32]         --\n",
       "│    │    └─Conv2d: 3-20                 [64, 128, 32, 32]         147,456\n",
       "│    │    └─BatchNorm2d: 3-21            [64, 128, 32, 32]         256\n",
       "│    │    └─ReLU: 3-22                   [64, 128, 32, 32]         --\n",
       "│    │    └─Conv2d: 3-23                 [64, 128, 32, 32]         147,456\n",
       "│    │    └─BatchNorm2d: 3-24            [64, 128, 32, 32]         256\n",
       "│    │    └─ReLU: 3-25                   [64, 128, 32, 32]         --\n",
       "├─Sequential: 1-7                        [64, 256, 16, 16]         --\n",
       "│    └─BasicBlock: 2-5                   [64, 256, 16, 16]         --\n",
       "│    │    └─Conv2d: 3-26                 [64, 256, 16, 16]         294,912\n",
       "│    │    └─BatchNorm2d: 3-27            [64, 256, 16, 16]         512\n",
       "│    │    └─ReLU: 3-28                   [64, 256, 16, 16]         --\n",
       "│    │    └─Conv2d: 3-29                 [64, 256, 16, 16]         589,824\n",
       "│    │    └─BatchNorm2d: 3-30            [64, 256, 16, 16]         512\n",
       "│    │    └─Sequential: 3-31             [64, 256, 16, 16]         33,280\n",
       "│    │    └─ReLU: 3-32                   [64, 256, 16, 16]         --\n",
       "│    └─BasicBlock: 2-6                   [64, 256, 16, 16]         --\n",
       "│    │    └─Conv2d: 3-33                 [64, 256, 16, 16]         589,824\n",
       "│    │    └─BatchNorm2d: 3-34            [64, 256, 16, 16]         512\n",
       "│    │    └─ReLU: 3-35                   [64, 256, 16, 16]         --\n",
       "│    │    └─Conv2d: 3-36                 [64, 256, 16, 16]         589,824\n",
       "│    │    └─BatchNorm2d: 3-37            [64, 256, 16, 16]         512\n",
       "│    │    └─ReLU: 3-38                   [64, 256, 16, 16]         --\n",
       "├─Sequential: 1-8                        [64, 512, 8, 8]           --\n",
       "│    └─BasicBlock: 2-7                   [64, 512, 8, 8]           --\n",
       "│    │    └─Conv2d: 3-39                 [64, 512, 8, 8]           1,179,648\n",
       "│    │    └─BatchNorm2d: 3-40            [64, 512, 8, 8]           1,024\n",
       "│    │    └─ReLU: 3-41                   [64, 512, 8, 8]           --\n",
       "│    │    └─Conv2d: 3-42                 [64, 512, 8, 8]           2,359,296\n",
       "│    │    └─BatchNorm2d: 3-43            [64, 512, 8, 8]           1,024\n",
       "│    │    └─Sequential: 3-44             [64, 512, 8, 8]           132,096\n",
       "│    │    └─ReLU: 3-45                   [64, 512, 8, 8]           --\n",
       "│    └─BasicBlock: 2-8                   [64, 512, 8, 8]           --\n",
       "│    │    └─Conv2d: 3-46                 [64, 512, 8, 8]           2,359,296\n",
       "│    │    └─BatchNorm2d: 3-47            [64, 512, 8, 8]           1,024\n",
       "│    │    └─ReLU: 3-48                   [64, 512, 8, 8]           --\n",
       "│    │    └─Conv2d: 3-49                 [64, 512, 8, 8]           2,359,296\n",
       "│    │    └─BatchNorm2d: 3-50            [64, 512, 8, 8]           1,024\n",
       "│    │    └─ReLU: 3-51                   [64, 512, 8, 8]           --\n",
       "├─AdaptiveAvgPool2d: 1-9                 [64, 512, 1, 1]           --\n",
       "├─Sequential: 1-10                       [64, 2]                   --\n",
       "│    └─Linear: 2-9                       [64, 2]                   1,026\n",
       "==========================================================================================\n",
       "Total params: 11,177,538\n",
       "Trainable params: 11,177,538\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 151.60\n",
       "==========================================================================================\n",
       "Input size (MB): 50.33\n",
       "Forward/backward pass size (MB): 3321.89\n",
       "Params size (MB): 44.71\n",
       "Estimated Total Size (MB): 3416.93\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_resnet18.fc = nn.Sequential(nn.Linear(in_features=512, out_features=2, bias=True))\n",
    "\n",
    "# get a summary of the model based on our input shape\n",
    "model_resnet18.to(device)\n",
    "input_size = tuple([batch_size]) + tuple(img.shape)\n",
    "summary(model_resnet18, input_size=input_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "broad-married",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statistics import mean\n",
    "\n",
    "class LoggedVariable:\n",
    "    def __init__(self):\n",
    "        self.batch_values = []\n",
    "        self.epoch_values = []\n",
    "        \n",
    "    def append(self, value):\n",
    "        self.batch_values.append(value)\n",
    "        \n",
    "    def end_epoch(self):\n",
    "        mean_batch_values = mean(self.batch_values)\n",
    "        self.epoch_values.append(mean_batch_values)\n",
    "        self.batch_values = []\n",
    "        \n",
    "class Logger:\n",
    "    def __init__(self):\n",
    "        self.variables = {}\n",
    "    \n",
    "    def __call__(self, key, value):\n",
    "        if key not in self.variables:\n",
    "            self.variables[key] = LoggedVariable()\n",
    "        self.variables[key].append(value)\n",
    "    \n",
    "    def end_epoch(self, epoch):\n",
    "        print(f\"end epoch {epoch}\", end = '')\n",
    "        for key, val in self.variables.items():\n",
    "            val.end_epoch()\n",
    "            print(f\" {key}: {val.epoch_values[epoch]:.2f}\", end = '')\n",
    "        print()\n",
    "    \n",
    "    def history(self):\n",
    "        return { k:v.epoch_values for k, v in self.variables.items() }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ruled-colleague",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(logits, y):\n",
    "    pred = torch.log_softmax(logits, dim=1)\n",
    "    correct = pred.argmax(dim=1).eq(y).sum().item()\n",
    "    total = len(y)\n",
    "    acc = correct / total\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "organized-freeze",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitting model: ResNet for 30 epochs.\n",
      "Epoch 0\n",
      "train.\t\tepoch: 0\tbatch: 1094/1094\tloss: 0.249\taccuracy: 0.917 \n",
      "validate.\tepoch: 0\tbatch: 469/469\t\tloss: 0.267\taccuracy: 0.917 \n",
      "saving checkpoint to /home/ubuntu/pathgen/experiments/new/ResNet_checkpoint_0.ckpt\n",
      "end epoch 0 train_acc: 0.83 train_loss: 0.41 valid_acc: 0.83 valid_loss: 0.40\n",
      "\n",
      "Epoch 1\n",
      "train.\t\tepoch: 1\tbatch: 1094/1094\tloss: 0.280\taccuracy: 0.917 \n",
      "validate.\tepoch: 1\tbatch: 469/469\t\tloss: 0.282\taccuracy: 0.896 \n",
      "saving checkpoint to /home/ubuntu/pathgen/experiments/new/ResNet_checkpoint_1.ckpt\n",
      "end epoch 1 train_acc: 0.87 train_loss: 0.30 valid_acc: 0.87 valid_loss: 0.34\n",
      "\n",
      "Epoch 2\n",
      "train.\t\tepoch: 2\tbatch: 1094/1094\tloss: 0.260\taccuracy: 0.917 \n",
      "validate.\tepoch: 2\tbatch: 469/469\t\tloss: 0.361\taccuracy: 0.854 \n",
      "saving checkpoint to /home/ubuntu/pathgen/experiments/new/ResNet_checkpoint_2.ckpt\n",
      "end epoch 2 train_acc: 0.89 train_loss: 0.26 valid_acc: 0.86 valid_loss: 0.34\n",
      "\n",
      "Epoch 3\n",
      "train.\t\tepoch: 3\tbatch: 1094/1094\tloss: 0.312\taccuracy: 0.854 \n",
      "validate.\tepoch: 3\tbatch: 469/469\t\tloss: 0.372\taccuracy: 0.896 \n",
      "saving checkpoint to /home/ubuntu/pathgen/experiments/new/ResNet_checkpoint_3.ckpt\n",
      "end epoch 3 train_acc: 0.91 train_loss: 0.23 valid_acc: 0.87 valid_loss: 0.32\n",
      "\n",
      "Epoch 4\n",
      "train.\t\tepoch: 4\tbatch: 1094/1094\tloss: 0.136\taccuracy: 0.979 \n",
      "validate.\tepoch: 4\tbatch: 469/469\t\tloss: 0.327\taccuracy: 0.854 \n",
      "saving checkpoint to /home/ubuntu/pathgen/experiments/new/ResNet_checkpoint_4.ckpt\n",
      "end epoch 4 train_acc: 0.92 train_loss: 0.21 valid_acc: 0.87 valid_loss: 0.34\n",
      "\n",
      "Epoch 5\n",
      "train.\t\tepoch: 5\tbatch: 1094/1094\tloss: 0.164\taccuracy: 0.938 \n",
      "validate.\tepoch: 5\tbatch: 469/469\t\tloss: 0.404\taccuracy: 0.750 \n",
      "saving checkpoint to /home/ubuntu/pathgen/experiments/new/ResNet_checkpoint_5.ckpt\n",
      "end epoch 5 train_acc: 0.93 train_loss: 0.19 valid_acc: 0.88 valid_loss: 0.32\n",
      "\n",
      "Epoch 6\n",
      "train.\t\tepoch: 6\tbatch: 1094/1094\tloss: 0.134\taccuracy: 0.917 \n",
      "validate.\tepoch: 6\tbatch: 469/469\t\tloss: 0.437\taccuracy: 0.833 \n",
      "saving checkpoint to /home/ubuntu/pathgen/experiments/new/ResNet_checkpoint_6.ckpt\n",
      "end epoch 6 train_acc: 0.93 train_loss: 0.18 valid_acc: 0.88 valid_loss: 0.33\n",
      "\n",
      "Epoch 7\n",
      "train.\t\tepoch: 7\tbatch: 1094/1094\tloss: 0.167\taccuracy: 0.938 \n",
      "validate.\tepoch: 7\tbatch: 469/469\t\tloss: 0.162\taccuracy: 0.938 \n",
      "saving checkpoint to /home/ubuntu/pathgen/experiments/new/ResNet_checkpoint_7.ckpt\n",
      "end epoch 7 train_acc: 0.94 train_loss: 0.17 valid_acc: 0.87 valid_loss: 0.33\n",
      "\n",
      "Epoch 8\n",
      "train.\t\tepoch: 8\tbatch: 1094/1094\tloss: 0.072\taccuracy: 1.000 \n",
      "validate.\tepoch: 8\tbatch: 469/469\t\tloss: 0.295\taccuracy: 0.875 \n",
      "saving checkpoint to /home/ubuntu/pathgen/experiments/new/ResNet_checkpoint_8.ckpt\n",
      "end epoch 8 train_acc: 0.94 train_loss: 0.16 valid_acc: 0.88 valid_loss: 0.32\n",
      "\n",
      "Epoch 9\n",
      "train.\t\tepoch: 9\tbatch: 1094/1094\tloss: 0.157\taccuracy: 0.958 \n",
      "validate.\tepoch: 9\tbatch: 469/469\t\tloss: 0.383\taccuracy: 0.854 \n",
      "saving checkpoint to /home/ubuntu/pathgen/experiments/new/ResNet_checkpoint_9.ckpt\n",
      "end epoch 9 train_acc: 0.94 train_loss: 0.16 valid_acc: 0.87 valid_loss: 0.33\n",
      "\n",
      "Epoch 10\n",
      "train.\t\tepoch: 10\tbatch: 1094/1094\tloss: 0.201\taccuracy: 0.938 \n",
      "validate.\tepoch: 10\tbatch: 469/469\t\tloss: 0.208\taccuracy: 0.917 \n",
      "saving checkpoint to /home/ubuntu/pathgen/experiments/new/ResNet_checkpoint_10.ckpt\n",
      "end epoch 10 train_acc: 0.94 train_loss: 0.16 valid_acc: 0.87 valid_loss: 0.33\n",
      "\n",
      "Epoch 11\n",
      "train.\t\tepoch: 11\tbatch: 1094/1094\tloss: 0.127\taccuracy: 0.958 \n",
      "validate.\tepoch: 11\tbatch: 469/469\t\tloss: 0.302\taccuracy: 0.854 \n",
      "saving checkpoint to /home/ubuntu/pathgen/experiments/new/ResNet_checkpoint_11.ckpt\n",
      "end epoch 11 train_acc: 0.94 train_loss: 0.16 valid_acc: 0.87 valid_loss: 0.33\n",
      "\n",
      "Epoch 12\n",
      "train.\t\tepoch: 12\tbatch: 1094/1094\tloss: 0.087\taccuracy: 1.000 \n",
      "validate.\tepoch: 12\tbatch: 469/469\t\tloss: 0.322\taccuracy: 0.833 \n",
      "saving checkpoint to /home/ubuntu/pathgen/experiments/new/ResNet_checkpoint_12.ckpt\n",
      "end epoch 12 train_acc: 0.94 train_loss: 0.16 valid_acc: 0.87 valid_loss: 0.33\n",
      "\n",
      "Epoch 13\n",
      "train.\t\tepoch: 13\tbatch: 1094/1094\tloss: 0.158\taccuracy: 0.958 \n",
      "validate.\tepoch: 13\tbatch: 469/469\t\tloss: 0.433\taccuracy: 0.833 \n",
      "saving checkpoint to /home/ubuntu/pathgen/experiments/new/ResNet_checkpoint_13.ckpt\n",
      "end epoch 13 train_acc: 0.94 train_loss: 0.16 valid_acc: 0.87 valid_loss: 0.34\n",
      "\n",
      "Epoch 14\n",
      "train.\t\tepoch: 14\tbatch: 1094/1094\tloss: 0.209\taccuracy: 0.938 \n",
      "validate.\tepoch: 14\tbatch: 469/469\t\tloss: 0.299\taccuracy: 0.896 \n",
      "saving checkpoint to /home/ubuntu/pathgen/experiments/new/ResNet_checkpoint_14.ckpt\n",
      "end epoch 14 train_acc: 0.94 train_loss: 0.16 valid_acc: 0.87 valid_loss: 0.34\n",
      "\n",
      "Epoch 15\n",
      "train.\t\tepoch: 15\tbatch: 1094/1094\tloss: 0.260\taccuracy: 0.938 \n",
      "validate.\tepoch: 15\tbatch: 469/469\t\tloss: 0.302\taccuracy: 0.875 \n",
      "saving checkpoint to /home/ubuntu/pathgen/experiments/new/ResNet_checkpoint_15.ckpt\n",
      "end epoch 15 train_acc: 0.94 train_loss: 0.16 valid_acc: 0.87 valid_loss: 0.33\n",
      "\n",
      "Epoch 16\n",
      "train.\t\tepoch: 16\tbatch: 1094/1094\tloss: 0.140\taccuracy: 0.938 \n",
      "validate.\tepoch: 16\tbatch: 469/469\t\tloss: 0.178\taccuracy: 0.938 \n",
      "saving checkpoint to /home/ubuntu/pathgen/experiments/new/ResNet_checkpoint_16.ckpt\n",
      "end epoch 16 train_acc: 0.94 train_loss: 0.16 valid_acc: 0.87 valid_loss: 0.34\n",
      "\n",
      "Epoch 17\n",
      "train.\t\tepoch: 17\tbatch: 1094/1094\tloss: 0.170\taccuracy: 0.938 \n",
      "validate.\tepoch: 17\tbatch: 469/469\t\tloss: 0.149\taccuracy: 0.958 \n",
      "saving checkpoint to /home/ubuntu/pathgen/experiments/new/ResNet_checkpoint_17.ckpt\n",
      "end epoch 17 train_acc: 0.94 train_loss: 0.16 valid_acc: 0.87 valid_loss: 0.33\n",
      "\n",
      "Epoch 18\n",
      "train.\t\tepoch: 18\tbatch: 1094/1094\tloss: 0.087\taccuracy: 1.000 \n",
      "validate.\tepoch: 18\tbatch: 469/469\t\tloss: 0.410\taccuracy: 0.812 \n",
      "saving checkpoint to /home/ubuntu/pathgen/experiments/new/ResNet_checkpoint_18.ckpt\n",
      "end epoch 18 train_acc: 0.94 train_loss: 0.16 valid_acc: 0.87 valid_loss: 0.33\n",
      "\n",
      "Epoch 19\n",
      "train.\t\tepoch: 19\tbatch: 1094/1094\tloss: 0.123\taccuracy: 0.917 \n",
      "validate.\tepoch: 19\tbatch: 469/469\t\tloss: 0.246\taccuracy: 0.917 \n",
      "saving checkpoint to /home/ubuntu/pathgen/experiments/new/ResNet_checkpoint_19.ckpt\n",
      "end epoch 19 train_acc: 0.94 train_loss: 0.16 valid_acc: 0.87 valid_loss: 0.34\n",
      "\n",
      "Epoch 20\n",
      "train.\t\tepoch: 20\tbatch: 1094/1094\tloss: 0.123\taccuracy: 0.979 \n",
      "validate.\tepoch: 20\tbatch: 469/469\t\tloss: 0.632\taccuracy: 0.812 \n",
      "saving checkpoint to /home/ubuntu/pathgen/experiments/new/ResNet_checkpoint_20.ckpt\n",
      "end epoch 20 train_acc: 0.94 train_loss: 0.16 valid_acc: 0.87 valid_loss: 0.33\n",
      "\n",
      "Epoch 21\n",
      "train.\t\tepoch: 21\tbatch: 1094/1094\tloss: 0.231\taccuracy: 0.917 \n",
      "validate.\tepoch: 21\tbatch: 469/469\t\tloss: 0.218\taccuracy: 0.917 \n",
      "saving checkpoint to /home/ubuntu/pathgen/experiments/new/ResNet_checkpoint_21.ckpt\n",
      "end epoch 21 train_acc: 0.94 train_loss: 0.16 valid_acc: 0.87 valid_loss: 0.34\n",
      "\n",
      "Epoch 22\n",
      "train.\t\tepoch: 22\tbatch: 1094/1094\tloss: 0.257\taccuracy: 0.875 \n",
      "validate.\tepoch: 22\tbatch: 469/469\t\tloss: 0.294\taccuracy: 0.875 \n",
      "saving checkpoint to /home/ubuntu/pathgen/experiments/new/ResNet_checkpoint_22.ckpt\n",
      "end epoch 22 train_acc: 0.94 train_loss: 0.15 valid_acc: 0.87 valid_loss: 0.33\n",
      "\n",
      "Epoch 23\n",
      "train.\t\tepoch: 23\tbatch: 1094/1094\tloss: 0.117\taccuracy: 0.958 \n",
      "validate.\tepoch: 23\tbatch: 469/469\t\tloss: 0.301\taccuracy: 0.875 \n",
      "saving checkpoint to /home/ubuntu/pathgen/experiments/new/ResNet_checkpoint_23.ckpt\n",
      "end epoch 23 train_acc: 0.94 train_loss: 0.16 valid_acc: 0.87 valid_loss: 0.34\n",
      "\n",
      "Epoch 24\n",
      "train.\t\tepoch: 24\tbatch: 1094/1094\tloss: 0.124\taccuracy: 0.958 \n",
      "validate.\tepoch: 24\tbatch: 469/469\t\tloss: 0.274\taccuracy: 0.917 \n",
      "saving checkpoint to /home/ubuntu/pathgen/experiments/new/ResNet_checkpoint_24.ckpt\n",
      "end epoch 24 train_acc: 0.94 train_loss: 0.16 valid_acc: 0.87 valid_loss: 0.33\n",
      "\n",
      "Epoch 25\n",
      "train.\t\tepoch: 25\tbatch: 1094/1094\tloss: 0.108\taccuracy: 0.958 \n",
      "validate.\tepoch: 25\tbatch: 469/469\t\tloss: 0.497\taccuracy: 0.792 \n",
      "saving checkpoint to /home/ubuntu/pathgen/experiments/new/ResNet_checkpoint_25.ckpt\n",
      "end epoch 25 train_acc: 0.94 train_loss: 0.16 valid_acc: 0.87 valid_loss: 0.33\n",
      "\n",
      "Epoch 26\n",
      "train.\t\tepoch: 26\tbatch: 1094/1094\tloss: 0.148\taccuracy: 0.938 \n",
      "validate.\tepoch: 26\tbatch: 469/469\t\tloss: 0.244\taccuracy: 0.896 \n",
      "saving checkpoint to /home/ubuntu/pathgen/experiments/new/ResNet_checkpoint_26.ckpt\n",
      "end epoch 26 train_acc: 0.94 train_loss: 0.15 valid_acc: 0.87 valid_loss: 0.33\n",
      "\n",
      "Epoch 27\n",
      "train.\t\tepoch: 27\tbatch: 1094/1094\tloss: 0.173\taccuracy: 0.979 \n",
      "validate.\tepoch: 27\tbatch: 469/469\t\tloss: 0.520\taccuracy: 0.896 \n",
      "saving checkpoint to /home/ubuntu/pathgen/experiments/new/ResNet_checkpoint_27.ckpt\n",
      "end epoch 27 train_acc: 0.94 train_loss: 0.16 valid_acc: 0.87 valid_loss: 0.33\n",
      "\n",
      "Epoch 28\n",
      "train.\t\tepoch: 28\tbatch: 1094/1094\tloss: 0.076\taccuracy: 1.000 \n",
      "validate.\tepoch: 28\tbatch: 469/469\t\tloss: 0.490\taccuracy: 0.792 \n",
      "saving checkpoint to /home/ubuntu/pathgen/experiments/new/ResNet_checkpoint_28.ckpt\n",
      "end epoch 28 train_acc: 0.94 train_loss: 0.16 valid_acc: 0.87 valid_loss: 0.33\n",
      "\n",
      "Epoch 29\n",
      "train.\t\tepoch: 29\tbatch: 1094/1094\tloss: 0.097\taccuracy: 0.938 \n",
      "validate.\tepoch: 29\tbatch: 469/469\t\tloss: 0.262\taccuracy: 0.917 \n",
      "saving checkpoint to /home/ubuntu/pathgen/experiments/new/ResNet_checkpoint_29.ckpt\n",
      "end epoch 29 train_acc: 0.94 train_loss: 0.16 valid_acc: 0.87 valid_loss: 0.34\n",
      "\n",
      "training complete.\n",
      "Time total:     4745.87 sec\n",
      "Time per epoch: 158.20 sec\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "import json\n",
    "\n",
    "model = model_resnet18\n",
    "\n",
    "print(f'fitting model: {type(model).__name__} for {num_epochs} epochs.')\n",
    "\n",
    "# set up the optimizer\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9, weight_decay=0.001)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.5)\n",
    "\n",
    "# initalise stats\n",
    "log = Logger()\n",
    "start_time_sec = time()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"Epoch {epoch}\")\n",
    "    \n",
    "    # train and evaluate on the training set\n",
    "    model.train()\n",
    "    for batch_idx, (X, y) in enumerate(train_loader):\n",
    "        # put X and y for the batch on the GPU is possible\n",
    "        X = X.to(device)\n",
    "        y = y.to(device)\n",
    "\n",
    "        # forward pass\n",
    "        logits = model(X)\n",
    "        loss = criterion(logits, y)\n",
    "\n",
    "        # backwards pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        # gradient descent\n",
    "        optimizer.step()\n",
    "\n",
    "        # log the metrics\n",
    "        acc = accuracy(logits, y)\n",
    "        log('train_acc', acc)\n",
    "        log('train_loss', loss.item())\n",
    "\n",
    "        print('\\r', f'train.\\t\\tepoch: {epoch}\\tbatch: {batch_idx + 1}/{len(train_loader)}\\tloss: {loss:.3f}\\taccuracy: {acc:.3f} ', sep='', end='', flush=True)\n",
    "        # print(torch.log_softmax(logits, dim=1).argmax(dim=1), y)\n",
    "        # print(f'train.\\t\\tepoch: {epoch}\\tbatch: {batch_idx + 1}/{len(train_loader)}\\tloss: {loss:.3f}\\taccuracy: {acc:.3f}')\n",
    "    print()\n",
    "\n",
    "    # evaluate on the validation set\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (X, y) in enumerate(valid_loader):\n",
    "            # put X and y for the batch on the GPU is possible\n",
    "            X = X.to(device)\n",
    "            y = y.to(device)\n",
    "\n",
    "            # forward pass\n",
    "            logits = model(X)\n",
    "            loss = criterion(logits, y)\n",
    "\n",
    "            # computer the metric and log them\n",
    "            acc = accuracy(logits, y)\n",
    "            log('valid_acc', acc)\n",
    "            log('valid_loss', loss.item())\n",
    "\n",
    "            print('\\r', f'validate.\\tepoch: {epoch}\\tbatch: {batch_idx + 1}/{len(valid_loader)}\\t\\tloss: {loss:.3f}\\taccuracy: {acc:.3f} ', sep='', end='', flush=True)        \n",
    "\n",
    "    print()\n",
    "\n",
    "    save_checkpoint(epoch, model, optimizer, experiment_root / f\"{type(model).__name__}_checkpoint_{epoch}.ckpt\") \n",
    "    log.end_epoch(epoch)\n",
    "\n",
    "    scheduler.step()\n",
    "    print()\n",
    "\n",
    "end_time_sec       = time()\n",
    "total_time_sec     = end_time_sec - start_time_sec\n",
    "time_per_epoch_sec = total_time_sec / num_epochs\n",
    "print(\"training complete.\")\n",
    "print('Time total:     %5.2f sec' % (total_time_sec))\n",
    "print('Time per epoch: %5.2f sec' % (time_per_epoch_sec))\n",
    "print()\n",
    "\n",
    "history = log.history()\n",
    "\n",
    "# save the results\n",
    "json.dump(history, open(experiment_root / f\"results_{type(model).__name__}.json\", \"w\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "timely-chase",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pathgen",
   "language": "python",
   "name": "pathgen"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
