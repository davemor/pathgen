{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "mounted-queen",
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard project preamble\n",
    "from pathgen.utils.seeds import set_seed\n",
    "from pathgen.utils.paths import project_root\n",
    "\n",
    "experiment_name = \"new\"\n",
    "experiment_root = project_root() / \"experiments\" / experiment_name\n",
    "\n",
    "global_seed = 987654321\n",
    "set_seed(global_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "plain-display",
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard data science imports\n",
    "import numpy as np\n",
    "\n",
    "# standard pytorch imports\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "# pytorch data loading imports\n",
    "from torch.utils.data import DataLoader, RandomSampler\n",
    "from torchvision.datasets import ImageFolder\n",
    "\n",
    "# torchvision\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "advised-parker",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define our hyper parameters\n",
    "batch_size = 64\n",
    "num_epochs = 10\n",
    "learning_rate = 0.01  # 0.001 - takes 25mins (log10 grid search?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "double-shade",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "hazardous-spyware",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up the data loaders for training\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])  # these values are what the pretrained models expect\n",
    "])\n",
    "\n",
    "train_set = ImageFolder(experiment_root / 'train_patches', transform=transform)  # 70,000 samples (35,000 per class) - non-fake\n",
    "valid_set = ImageFolder(experiment_root / 'valid_patches', transform=transform)  # 30,000 samples (15,000 per class) - non-fake\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True, worker_init_fn=np.random.seed(global_seed), num_workers=32)\n",
    "valid_loader = DataLoader(valid_set, batch_size=batch_size, shuffle=True, worker_init_fn=np.random.seed(global_seed), num_workers=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "accomplished-puzzle",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(epoch, model, optimizer, path):\n",
    "    print(f\"saving checkpoint to {path}\")\n",
    "    state = { 'epoch': epoch, \n",
    "              'model_state_dict': model.state_dict(),\n",
    "              'optimizer_state_dict': optimizer.state_dict() }\n",
    "    torch.save(state, path)\n",
    "\n",
    "def load_checkpoint(model, optimizer, path):\n",
    "    print(\"loading checkpoint\")\n",
    "    state = torch.load(path)\n",
    "    epoch = state[\"epoch\"]\n",
    "    model.load_state_dict(state[\"state_dict\"])\n",
    "    optimizer.load_state_dict(state[\"optimizer\"])\n",
    "    return epoch, model, optimizer, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "standing-roller",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preamble\n",
    "from torchinfo import summary\n",
    "\n",
    "# get and example image from the dataset so we can generate the summaries\n",
    "img, _ = train_set[0]\n",
    "img = img.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "optional-brave",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_resnet18 = torchvision.models.resnet18(pretrained=False)\n",
    "model_resnet18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "confident-costs",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "ResNet                                   --                        --\n",
       "├─Conv2d: 1-1                            [64, 64, 128, 128]        9,408\n",
       "├─BatchNorm2d: 1-2                       [64, 64, 128, 128]        128\n",
       "├─ReLU: 1-3                              [64, 64, 128, 128]        --\n",
       "├─MaxPool2d: 1-4                         [64, 64, 64, 64]          --\n",
       "├─Sequential: 1-5                        [64, 64, 64, 64]          --\n",
       "│    └─BasicBlock: 2-1                   [64, 64, 64, 64]          --\n",
       "│    │    └─Conv2d: 3-1                  [64, 64, 64, 64]          36,864\n",
       "│    │    └─BatchNorm2d: 3-2             [64, 64, 64, 64]          128\n",
       "│    │    └─ReLU: 3-3                    [64, 64, 64, 64]          --\n",
       "│    │    └─Conv2d: 3-4                  [64, 64, 64, 64]          36,864\n",
       "│    │    └─BatchNorm2d: 3-5             [64, 64, 64, 64]          128\n",
       "│    │    └─ReLU: 3-6                    [64, 64, 64, 64]          --\n",
       "│    └─BasicBlock: 2-2                   [64, 64, 64, 64]          --\n",
       "│    │    └─Conv2d: 3-7                  [64, 64, 64, 64]          36,864\n",
       "│    │    └─BatchNorm2d: 3-8             [64, 64, 64, 64]          128\n",
       "│    │    └─ReLU: 3-9                    [64, 64, 64, 64]          --\n",
       "│    │    └─Conv2d: 3-10                 [64, 64, 64, 64]          36,864\n",
       "│    │    └─BatchNorm2d: 3-11            [64, 64, 64, 64]          128\n",
       "│    │    └─ReLU: 3-12                   [64, 64, 64, 64]          --\n",
       "├─Sequential: 1-6                        [64, 128, 32, 32]         --\n",
       "│    └─BasicBlock: 2-3                   [64, 128, 32, 32]         --\n",
       "│    │    └─Conv2d: 3-13                 [64, 128, 32, 32]         73,728\n",
       "│    │    └─BatchNorm2d: 3-14            [64, 128, 32, 32]         256\n",
       "│    │    └─ReLU: 3-15                   [64, 128, 32, 32]         --\n",
       "│    │    └─Conv2d: 3-16                 [64, 128, 32, 32]         147,456\n",
       "│    │    └─BatchNorm2d: 3-17            [64, 128, 32, 32]         256\n",
       "│    │    └─Sequential: 3-18             [64, 128, 32, 32]         8,448\n",
       "│    │    └─ReLU: 3-19                   [64, 128, 32, 32]         --\n",
       "│    └─BasicBlock: 2-4                   [64, 128, 32, 32]         --\n",
       "│    │    └─Conv2d: 3-20                 [64, 128, 32, 32]         147,456\n",
       "│    │    └─BatchNorm2d: 3-21            [64, 128, 32, 32]         256\n",
       "│    │    └─ReLU: 3-22                   [64, 128, 32, 32]         --\n",
       "│    │    └─Conv2d: 3-23                 [64, 128, 32, 32]         147,456\n",
       "│    │    └─BatchNorm2d: 3-24            [64, 128, 32, 32]         256\n",
       "│    │    └─ReLU: 3-25                   [64, 128, 32, 32]         --\n",
       "├─Sequential: 1-7                        [64, 256, 16, 16]         --\n",
       "│    └─BasicBlock: 2-5                   [64, 256, 16, 16]         --\n",
       "│    │    └─Conv2d: 3-26                 [64, 256, 16, 16]         294,912\n",
       "│    │    └─BatchNorm2d: 3-27            [64, 256, 16, 16]         512\n",
       "│    │    └─ReLU: 3-28                   [64, 256, 16, 16]         --\n",
       "│    │    └─Conv2d: 3-29                 [64, 256, 16, 16]         589,824\n",
       "│    │    └─BatchNorm2d: 3-30            [64, 256, 16, 16]         512\n",
       "│    │    └─Sequential: 3-31             [64, 256, 16, 16]         33,280\n",
       "│    │    └─ReLU: 3-32                   [64, 256, 16, 16]         --\n",
       "│    └─BasicBlock: 2-6                   [64, 256, 16, 16]         --\n",
       "│    │    └─Conv2d: 3-33                 [64, 256, 16, 16]         589,824\n",
       "│    │    └─BatchNorm2d: 3-34            [64, 256, 16, 16]         512\n",
       "│    │    └─ReLU: 3-35                   [64, 256, 16, 16]         --\n",
       "│    │    └─Conv2d: 3-36                 [64, 256, 16, 16]         589,824\n",
       "│    │    └─BatchNorm2d: 3-37            [64, 256, 16, 16]         512\n",
       "│    │    └─ReLU: 3-38                   [64, 256, 16, 16]         --\n",
       "├─Sequential: 1-8                        [64, 512, 8, 8]           --\n",
       "│    └─BasicBlock: 2-7                   [64, 512, 8, 8]           --\n",
       "│    │    └─Conv2d: 3-39                 [64, 512, 8, 8]           1,179,648\n",
       "│    │    └─BatchNorm2d: 3-40            [64, 512, 8, 8]           1,024\n",
       "│    │    └─ReLU: 3-41                   [64, 512, 8, 8]           --\n",
       "│    │    └─Conv2d: 3-42                 [64, 512, 8, 8]           2,359,296\n",
       "│    │    └─BatchNorm2d: 3-43            [64, 512, 8, 8]           1,024\n",
       "│    │    └─Sequential: 3-44             [64, 512, 8, 8]           132,096\n",
       "│    │    └─ReLU: 3-45                   [64, 512, 8, 8]           --\n",
       "│    └─BasicBlock: 2-8                   [64, 512, 8, 8]           --\n",
       "│    │    └─Conv2d: 3-46                 [64, 512, 8, 8]           2,359,296\n",
       "│    │    └─BatchNorm2d: 3-47            [64, 512, 8, 8]           1,024\n",
       "│    │    └─ReLU: 3-48                   [64, 512, 8, 8]           --\n",
       "│    │    └─Conv2d: 3-49                 [64, 512, 8, 8]           2,359,296\n",
       "│    │    └─BatchNorm2d: 3-50            [64, 512, 8, 8]           1,024\n",
       "│    │    └─ReLU: 3-51                   [64, 512, 8, 8]           --\n",
       "├─AdaptiveAvgPool2d: 1-9                 [64, 512, 1, 1]           --\n",
       "├─Sequential: 1-10                       [64, 2]                   --\n",
       "│    └─Linear: 2-9                       [64, 2]                   1,026\n",
       "==========================================================================================\n",
       "Total params: 11,177,538\n",
       "Trainable params: 11,177,538\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 151.60\n",
       "==========================================================================================\n",
       "Input size (MB): 50.33\n",
       "Forward/backward pass size (MB): 3321.89\n",
       "Params size (MB): 44.71\n",
       "Estimated Total Size (MB): 3416.93\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_resnet18.fc = nn.Sequential(nn.Linear(in_features=512, out_features=2, bias=True))\n",
    "\n",
    "# get a summary of the model based on our input shape\n",
    "model_resnet18.to(device)\n",
    "input_size = tuple([batch_size]) + tuple(img.shape)\n",
    "summary(model_resnet18, input_size=input_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "formal-panic",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statistics import mean\n",
    "\n",
    "class LoggedVariable:\n",
    "    def __init__(self):\n",
    "        self.batch_values = []\n",
    "        self.epoch_values = []\n",
    "        \n",
    "    def append(self, value):\n",
    "        self.batch_values.append(value)\n",
    "        \n",
    "    def end_epoch(self):\n",
    "        mean_batch_values = mean(self.batch_values)\n",
    "        self.epoch_values.append(mean_batch_values)\n",
    "        self.batch_values = []\n",
    "        \n",
    "class Logger:\n",
    "    def __init__(self):\n",
    "        self.variables = {}\n",
    "    \n",
    "    def __call__(self, key, value):\n",
    "        if key not in self.variables:\n",
    "            self.variables[key] = LoggedVariable()\n",
    "        self.variables[key].append(value)\n",
    "    \n",
    "    def end_epoch(self, epoch):\n",
    "        print(f\"end epoch {epoch}\", end = '')\n",
    "        for key, val in self.variables.items():\n",
    "            val.end_epoch()\n",
    "            print(f\" {key}: {val.epoch_values[epoch]:.2f}\", end = '')\n",
    "        print()\n",
    "    \n",
    "    def history(self):\n",
    "        return { k:v.epoch_values for k, v in self.variables.items() }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "russian-contest",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(logits, y):\n",
    "    pred = torch.log_softmax(logits, dim=1)\n",
    "    correct = pred.argmax(dim=1).eq(y).sum().item()\n",
    "    total = len(y)\n",
    "    acc = correct / total\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "copyrighted-modem",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitting model: ResNet for 10 epochs.\n",
      "Epoch 0\n",
      "train.\t\tepoch: 0\tbatch: 1094/1094\tloss: 0.249\taccuracy: 0.917 \n",
      "validate.\tepoch: 0\tbatch: 469/469\t\tloss: 0.267\taccuracy: 0.917 \n",
      "saving checkpoint to /home/ubuntu/pathgen/experiments/new/ResNet_checkpoint_0.ckpt\n",
      "end epoch 0 train_acc: 0.83 train_loss: 0.41 valid_acc: 0.83 valid_loss: 0.40\n",
      "\n",
      "Epoch 1\n",
      "train.\t\tepoch: 1\tbatch: 1094/1094\tloss: 0.280\taccuracy: 0.917 \n",
      "validate.\tepoch: 1\tbatch: 469/469\t\tloss: 0.282\taccuracy: 0.896 \n",
      "saving checkpoint to /home/ubuntu/pathgen/experiments/new/ResNet_checkpoint_1.ckpt\n",
      "end epoch 1 train_acc: 0.87 train_loss: 0.30 valid_acc: 0.87 valid_loss: 0.34\n",
      "\n",
      "Epoch 2\n",
      "train.\t\tepoch: 2\tbatch: 1094/1094\tloss: 0.260\taccuracy: 0.917 \n",
      "validate.\tepoch: 2\tbatch: 469/469\t\tloss: 0.361\taccuracy: 0.854 \n",
      "saving checkpoint to /home/ubuntu/pathgen/experiments/new/ResNet_checkpoint_2.ckpt\n",
      "end epoch 2 train_acc: 0.89 train_loss: 0.26 valid_acc: 0.86 valid_loss: 0.34\n",
      "\n",
      "Epoch 3\n",
      "train.\t\tepoch: 3\tbatch: 1094/1094\tloss: 0.312\taccuracy: 0.854 \n",
      "validate.\tepoch: 3\tbatch: 469/469\t\tloss: 0.372\taccuracy: 0.896 \n",
      "saving checkpoint to /home/ubuntu/pathgen/experiments/new/ResNet_checkpoint_3.ckpt\n",
      "end epoch 3 train_acc: 0.91 train_loss: 0.23 valid_acc: 0.87 valid_loss: 0.32\n",
      "\n",
      "Epoch 4\n",
      "train.\t\tepoch: 4\tbatch: 1094/1094\tloss: 0.136\taccuracy: 0.979 \n",
      "validate.\tepoch: 4\tbatch: 469/469\t\tloss: 0.327\taccuracy: 0.854 \n",
      "saving checkpoint to /home/ubuntu/pathgen/experiments/new/ResNet_checkpoint_4.ckpt\n",
      "end epoch 4 train_acc: 0.92 train_loss: 0.21 valid_acc: 0.87 valid_loss: 0.34\n",
      "\n",
      "Epoch 5\n",
      "train.\t\tepoch: 5\tbatch: 1094/1094\tloss: 0.164\taccuracy: 0.938 \n",
      "validate.\tepoch: 5\tbatch: 469/469\t\tloss: 0.404\taccuracy: 0.750 \n",
      "saving checkpoint to /home/ubuntu/pathgen/experiments/new/ResNet_checkpoint_5.ckpt\n",
      "end epoch 5 train_acc: 0.93 train_loss: 0.19 valid_acc: 0.88 valid_loss: 0.32\n",
      "\n",
      "Epoch 6\n",
      "train.\t\tepoch: 6\tbatch: 1094/1094\tloss: 0.134\taccuracy: 0.917 \n",
      "validate.\tepoch: 6\tbatch: 469/469\t\tloss: 0.437\taccuracy: 0.833 \n",
      "saving checkpoint to /home/ubuntu/pathgen/experiments/new/ResNet_checkpoint_6.ckpt\n",
      "end epoch 6 train_acc: 0.93 train_loss: 0.18 valid_acc: 0.88 valid_loss: 0.33\n",
      "\n",
      "Epoch 7\n",
      "train.\t\tepoch: 7\tbatch: 1094/1094\tloss: 0.167\taccuracy: 0.938 \n",
      "validate.\tepoch: 7\tbatch: 469/469\t\tloss: 0.162\taccuracy: 0.938 \n",
      "saving checkpoint to /home/ubuntu/pathgen/experiments/new/ResNet_checkpoint_7.ckpt\n",
      "end epoch 7 train_acc: 0.94 train_loss: 0.17 valid_acc: 0.87 valid_loss: 0.33\n",
      "\n",
      "Epoch 8\n",
      "train.\t\tepoch: 8\tbatch: 1094/1094\tloss: 0.072\taccuracy: 1.000 \n",
      "validate.\tepoch: 8\tbatch: 469/469\t\tloss: 0.295\taccuracy: 0.875 \n",
      "saving checkpoint to /home/ubuntu/pathgen/experiments/new/ResNet_checkpoint_8.ckpt\n",
      "end epoch 8 train_acc: 0.94 train_loss: 0.16 valid_acc: 0.88 valid_loss: 0.32\n",
      "\n",
      "Epoch 9\n",
      "train.\t\tepoch: 9\tbatch: 1094/1094\tloss: 0.157\taccuracy: 0.958 \n",
      "validate.\tepoch: 9\tbatch: 469/469\t\tloss: 0.383\taccuracy: 0.854 \n",
      "saving checkpoint to /home/ubuntu/pathgen/experiments/new/ResNet_checkpoint_9.ckpt\n",
      "end epoch 9 train_acc: 0.94 train_loss: 0.16 valid_acc: 0.87 valid_loss: 0.33\n",
      "\n",
      "training complete.\n",
      "Time total:     1612.19 sec\n",
      "Time per epoch: 161.22 sec\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "import json\n",
    "\n",
    "model = model_resnet18\n",
    "\n",
    "print(f'fitting model: {type(model).__name__} for {num_epochs} epochs.')\n",
    "\n",
    "# set up the optimizer\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9, weight_decay=0.001)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.5)\n",
    "\n",
    "# initalise stats\n",
    "log = Logger()\n",
    "start_time_sec = time()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"Epoch {epoch}\")\n",
    "    \n",
    "    # train and evaluate on the training set\n",
    "    model.train()\n",
    "    for batch_idx, (X, y) in enumerate(train_loader):\n",
    "        # put X and y for the batch on the GPU is possible\n",
    "        X = X.to(device)\n",
    "        y = y.to(device)\n",
    "\n",
    "        # forward pass\n",
    "        logits = model(X)\n",
    "        loss = criterion(logits, y)\n",
    "\n",
    "        # backwards pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        # gradient descent\n",
    "        optimizer.step()\n",
    "\n",
    "        # log the metrics\n",
    "        acc = accuracy(logits, y)\n",
    "        log('train_acc', acc)\n",
    "        log('train_loss', loss.item())\n",
    "\n",
    "        print('\\r', f'train.\\t\\tepoch: {epoch}\\tbatch: {batch_idx + 1}/{len(train_loader)}\\tloss: {loss:.3f}\\taccuracy: {acc:.3f} ', sep='', end='', flush=True)\n",
    "        # print(torch.log_softmax(logits, dim=1).argmax(dim=1), y)\n",
    "        # print(f'train.\\t\\tepoch: {epoch}\\tbatch: {batch_idx + 1}/{len(train_loader)}\\tloss: {loss:.3f}\\taccuracy: {acc:.3f}')\n",
    "    print()\n",
    "\n",
    "    # evaluate on the validation set\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (X, y) in enumerate(valid_loader):\n",
    "            # put X and y for the batch on the GPU is possible\n",
    "            X = X.to(device)\n",
    "            y = y.to(device)\n",
    "\n",
    "            # forward pass\n",
    "            logits = model(X)\n",
    "            loss = criterion(logits, y)\n",
    "\n",
    "            # computer the metric and log them\n",
    "            acc = accuracy(logits, y)\n",
    "            log('valid_acc', acc)\n",
    "            log('valid_loss', loss.item())\n",
    "\n",
    "            print('\\r', f'validate.\\tepoch: {epoch}\\tbatch: {batch_idx + 1}/{len(valid_loader)}\\t\\tloss: {loss:.3f}\\taccuracy: {acc:.3f} ', sep='', end='', flush=True)        \n",
    "\n",
    "    print()\n",
    "\n",
    "    save_checkpoint(epoch, model, optimizer, experiment_root / f\"{type(model).__name__}_checkpoint_{epoch}.ckpt\") \n",
    "    log.end_epoch(epoch)\n",
    "\n",
    "    scheduler.step()\n",
    "    print()\n",
    "\n",
    "end_time_sec       = time()\n",
    "total_time_sec     = end_time_sec - start_time_sec\n",
    "time_per_epoch_sec = total_time_sec / num_epochs\n",
    "print(\"training complete.\")\n",
    "print('Time total:     %5.2f sec' % (total_time_sec))\n",
    "print('Time per epoch: %5.2f sec' % (time_per_epoch_sec))\n",
    "print()\n",
    "\n",
    "history = log.history()\n",
    "\n",
    "# save the results\n",
    "json.dump(history, open(experiment_root / f\"results_{type(model).__name__}_realdata.json\", \"w\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "prerequisite-silence",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test\n",
    "test_set = ImageFolder(experiment_root / 'test_patches', transform=transform)\n",
    "test_loader = DataLoader(test_set, batch_size=batch_size, worker_init_fn=np.random.seed(global_seed), num_workers=32)\n",
    "\n",
    "expected, predicted = [], []\n",
    "\n",
    "# evaluate on the test set\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for batch_idx, (X, y) in enumerate(test_loader):\n",
    "        # put X and y for the batch on the GPU is possible\n",
    "        X = X.to(device)\n",
    "        y = y.to(device)\n",
    "\n",
    "        # forward pass\n",
    "        logits = model(X)\n",
    "\n",
    "        # computer the metric and log them\n",
    "        pred = torch.log_softmax(logits, dim=1).argmax(dim=1)\n",
    "        predicted.extend(pred.cpu().tolist())\n",
    "        expected.extend(y.cpu().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "happy-hampton",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      normal       0.80      0.91      0.85     15000\n",
      "       tumor       0.90      0.77      0.83     15000\n",
      "\n",
      "    accuracy                           0.84     30000\n",
      "   macro avg       0.85      0.84      0.84     30000\n",
      "weighted avg       0.85      0.84      0.84     30000\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(metrics.classification_report(expected, predicted, labels=[0, 1], target_names=['normal', 'tumor']))\n",
    "\n",
    "cm = metrics.confusion_matrix(expected, predicted)\n",
    "\n",
    "ax = plt.subplot()\n",
    "sns.heatmap(cm, annot=True, ax = ax, fmt='g', cmap='Blues');\n",
    "\n",
    "# labels, title and ticks\n",
    "ax.set_xlabel('Predicted labels');\n",
    "ax.set_ylabel('True labels'); \n",
    "ax.set_title('Patch Classifier Real Data Confusion Matrix'); \n",
    "ax.xaxis.set_ticklabels(['normal', 'tumor']); ax.yaxis.set_ticklabels(['normal', 'tumor']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "excited-tulsa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pathgen",
   "language": "python",
   "name": "pathgen"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
